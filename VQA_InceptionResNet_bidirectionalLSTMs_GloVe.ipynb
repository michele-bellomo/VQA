{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQA using InceptionResNet, bidirectional LSTM's blocks and <br> GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FiLwi7HcT6Zm"
   },
   "outputs": [],
   "source": [
    "# option to view all the outputs of a cell and not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJqHEF3eT6Zn"
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24631,
     "status": "ok",
     "timestamp": 1611312843386,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "41UUNZOHWyfX",
    "outputId": "febe82a3-56ef-43a2-da74-cd8901c2fdd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# the original file was implemented in Google Colab to take advantage of the free GPU \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf6aTmYFc6L5"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "executionInfo": {
     "elapsed": 18385,
     "status": "ok",
     "timestamp": 1611312859054,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "DWNtEUiOnrCZ",
    "outputId": "f1859ef3-b721-4bfa-f3cc-455d3e44e505"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>image_id</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who looks happier?</td>\n",
       "      <td>11779</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is the woman sitting?</td>\n",
       "      <td>11779</td>\n",
       "      <td>blanket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where is the man sitting?</td>\n",
       "      <td>11779</td>\n",
       "      <td>bench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this man hungry?</td>\n",
       "      <td>5536</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is holding the football?</td>\n",
       "      <td>16949</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       question image_id   answer\n",
       "0            Who looks happier?    11779      man\n",
       "1   Where is the woman sitting?    11779  blanket\n",
       "2     Where is the man sitting?    11779    bench\n",
       "3           Is this man hungry?     5536      yes\n",
       "4  Who is holding the football?    16949      man"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>image_id</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58832</td>\n",
       "      <td>58832</td>\n",
       "      <td>58832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>34035</td>\n",
       "      <td>28744</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>What color is the rug?</td>\n",
       "      <td>24606</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>387</td>\n",
       "      <td>3</td>\n",
       "      <td>18386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      question image_id answer\n",
       "count                    58832    58832  58832\n",
       "unique                   34035    28744     58\n",
       "top     What color is the rug?    24606    yes\n",
       "freq                       387        3  18386"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the questions\n",
    "dataset_dir = '/content/drive/My Drive/NeuralNetworks/VQA_Dataset'\n",
    "annotations_dir = os.path.join(dataset_dir, 'train_questions_annotations.json')\n",
    "annotations = pd.read_json(annotations_dir).transpose()\n",
    "annotations.reset_index(inplace=True, drop=True)\n",
    "annotations.head()\n",
    "annotations.describe()\n",
    "N = len(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All answers consist of a single word. Therefore, I can approach the problem as a classification task, where the target labels are the answers to the various questions. I use one-hot encoding to encode the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "executionInfo": {
     "elapsed": 18277,
     "status": "ok",
     "timestamp": 1611312860512,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "kKH9gZz6cRwz",
    "outputId": "380bfbfa-6c82-4085-f6b4-121c30aea5c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdb57783cc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classes' histograms  \n",
    "annotations[\"answer\"] = annotations[\"answer\"].astype('category')\n",
    "num_classes = annotations[\"answer\"].value_counts().count()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.countplot(y=\"answer\", data=annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XY9hiVXncRwz"
   },
   "source": [
    "As expected, some classes are way more represented than others (e.g. \"yes\" or \"no\"). <br>For this reason I will use a stratified sampling for the training/validation set division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shYZzJ55cRw0"
   },
   "outputs": [],
   "source": [
    "# Perform the one-hot encoding and add it to the dataset\n",
    "annotations['class_encoded'] = annotations[\"answer\"].cat.codes\n",
    "one_hot =  tf.keras.utils.to_categorical(annotations['class_encoded'])\n",
    "annotations[\"one_hot\"] = 0\n",
    "annotations[\"one_hot\"] = annotations[\"one_hot\"].astype(object)\n",
    "\n",
    "for i in range(N):\n",
    "    annotations.at[i, \"one_hot\"] = one_hot[i]\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75sNY9KBT6Zo"
   },
   "source": [
    "### GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSwuPYf9-K0V"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "max_qs_length = 21 \n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=10000, output_sequence_length=max_qs_length) \n",
    "vectorizer.adapt(annotations['question'].tolist())\n",
    "\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418504,
     "status": "ok",
     "timestamp": 1611313346845,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "OSimyhpm-3IM",
    "outputId": "8dc35a28-2662-4f40-9df7-3a9e5fae32b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-22 10:55:37--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-01-22 10:55:37--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-01-22 10:55:37--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  2.10MB/s    in 6m 26s  \n",
      "\n",
      "2021-01-22 11:02:03 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe embedding\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425061,
     "status": "ok",
     "timestamp": 1611313353744,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "rGTHCN53-3-l",
    "outputId": "d35078c1-ed9f-4494-ab1a-9eeafed43221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417930,
     "status": "ok",
     "timestamp": 1611313353746,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "nQtWO6oP_1LN",
    "outputId": "3321e6e9-8da6-4622-f465-6b71078cf8ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4528 words (65 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 32 \n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaBNL9co_9Xg"
   },
   "outputs": [],
   "source": [
    "# Embedding layer to be added to the model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 684970,
     "status": "ok",
     "timestamp": 1611313634428,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "1Nxf_uI5cRwy",
    "outputId": "b8a261dc-d1b6-4328-a901-f2c4fe27d5ff",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>image_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>class_encoded</th>\n",
       "      <th>one_hot</th>\n",
       "      <th>qs_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who looks happier?</td>\n",
       "      <td>11779</td>\n",
       "      <td>man</td>\n",
       "      <td>31</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[48, 804, 2059, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is the woman sitting?</td>\n",
       "      <td>11779</td>\n",
       "      <td>blanket</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[25, 3, 2, 16, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where is the man sitting?</td>\n",
       "      <td>11779</td>\n",
       "      <td>bench</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[25, 3, 2, 15, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this man hungry?</td>\n",
       "      <td>5536</td>\n",
       "      <td>yes</td>\n",
       "      <td>57</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3, 22, 15, 487, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is holding the football?</td>\n",
       "      <td>16949</td>\n",
       "      <td>man</td>\n",
       "      <td>31</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[48, 3, 50, 2, 235, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       question  ...                                       qs_tokenized\n",
       "0            Who looks happier?  ...  [48, 804, 2059, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1   Where is the woman sitting?  ...  [25, 3, 2, 16, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2     Where is the man sitting?  ...  [25, 3, 2, 15, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3           Is this man hungry?  ...  [3, 22, 15, 487, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "4  Who is holding the football?  ...  [48, 3, 50, 2, 235, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the embedded questions to the dataset\n",
    "annotations[\"qs_tokenized\"] = 0\n",
    "annotations[\"qs_tokenized\"] = annotations[\"qs_tokenized\"].astype(object)\n",
    "\n",
    "for i in range(N):\n",
    "    annotations.at[i, \"qs_tokenized\"] = vectorizer([annotations.at[i, \"question\"]]).numpy()[0]\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dklV3ALTcRw0"
   },
   "source": [
    "### Training/Validation splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 1169,
     "status": "ok",
     "timestamp": 1611313669241,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "FmQMXsV5cRw0",
    "outputId": "6ffbc216-067d-4612-80f3-1227407c4404"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>one_hot</th>\n",
       "      <th>qs_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11779</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[48, 804, 2059, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11779</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[25, 3, 2, 16, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11779</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[25, 3, 2, 15, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5536</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3, 22, 15, 487, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16949</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[48, 3, 50, 2, 235, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  ...                                       qs_tokenized\n",
       "0    11779  ...  [48, 804, 2059, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1    11779  ...  [25, 3, 2, 16, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2    11779  ...  [25, 3, 2, 15, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3     5536  ...  [3, 22, 15, 487, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "4    16949  ...  [48, 3, 50, 2, 235, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = annotations.drop(['question', 'answer', 'class_encoded'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PmSBDdtcRw1"
   },
   "outputs": [],
   "source": [
    "# Stratified sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = annotations['class_encoded']\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=SEED, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YAdgaRscRw1"
   },
   "source": [
    "### Costum Dataset creation to manage the images and questions flow during the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiGEFLf7cRw2"
   },
   "outputs": [],
   "source": [
    "# it is necessary to modify the class \"CustomDataset\" in order to create a flow of pairs of images and questions\n",
    "# for the training (this function is not currently implemented in keras)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "img_h = 299\n",
    "img_w = 299\n",
    "# Height and width of the original Inception ResNet architecture\n",
    "\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "\n",
    "    \"\"\"\n",
    "    CustomDataset inheriting from tf.keras.utils.Sequence.\n",
    "\n",
    "    3 main methods:\n",
    "      - __init__: save dataset params like directory, filenames..\n",
    "      - __len__: return the total number of samples in the dataset\n",
    "      - __getitem__: return a sample from the dataset\n",
    "\n",
    "    Note: \n",
    "      - the custom dataset return a single sample from the dataset. Then, we use \n",
    "        a tf.data.Dataset object to group samples into batches.\n",
    "      - in this case we have a different structure of the dataset in memory. \n",
    "        We have all the images in the same folder and the training and validation splits\n",
    "        are defined in text files.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, dataset_dir, preprocessing_function=None, out_shape=[img_h, img_w]):\n",
    "        subset_filenames = dataset['image_id'].tolist()\n",
    "        subset_tokenizedquestions = dataset['qs_tokenized'].tolist()\n",
    "        subset_classes = dataset['one_hot'].tolist()\n",
    "\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.subset_filenames = subset_filenames\n",
    "        self.subset_tokenizedquestions = subset_tokenizedquestions\n",
    "        self.subset_classes = subset_classes\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        self.out_shape = out_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Read Image\n",
    "        curr_filename = self.subset_filenames[index]\n",
    "        curr_question = self.subset_tokenizedquestions[index]\n",
    "        curr_class = self.subset_classes[index]\n",
    "        img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.png'))\n",
    "\n",
    "        # Resize image \n",
    "        img = img.resize(self.out_shape)\n",
    "        img_arr = np.array(img) \n",
    "        img_arr = img_arr[...,:3] # remove the fourth channel\n",
    "    \n",
    "        # Preprocess image\n",
    "        img_arr = self.preprocessing_function(img_arr)\n",
    "\n",
    "        return (img_arr, curr_question), curr_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8199,
     "status": "ok",
     "timestamp": 1611313685167,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "N0tMC5QWcRw2",
    "outputId": "f5589e18-fd6d-4147-adbb-196d894e12ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained-architecture...\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input \n",
    "base = tf.keras.applications.InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n",
    "base.trainable = False \n",
    "\n",
    "#... and give the correspondent preprocessing function as input to the CustomDataset\n",
    "dataset = CustomDataset(df_train, dataset_dir, preprocessing_function=preprocess_input)\n",
    "dataset_valid = CustomDataset(df_valid, dataset_dir, preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYORo9VRcRw2"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n",
    "                                               output_types=((tf.float32, tf.float32), tf.float32),\n",
    "                                               output_shapes=(([img_h, img_w, 3], [max_qs_length]), [num_classes]))\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
    "                                               output_types=((tf.float32, tf.float32),tf.float32),\n",
    "                                               output_shapes=(([img_h, img_w, 3], [max_qs_length]), [num_classes]))\n",
    "valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fyx28iuHT6Zp"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvnVkQ6AVs05"
   },
   "outputs": [],
   "source": [
    "# Import Keras \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "# Define CNN for Image Input\n",
    "image_input = Input(shape=(img_h, img_w, 3))\n",
    "x = base(image_input, training=False) \n",
    "encoded_image = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Define RNN for language input\n",
    "question_input = Input(shape=(max_qs_length))\n",
    "embedded_question = embedding_layer(question_input)\n",
    "\n",
    "#two LSTM blocks for bidirectional processing of the questions\n",
    "left = LSTM(128)(embedded_question)\n",
    "right = LSTM(128, go_backwards=True)(embedded_question)\n",
    "\n",
    "conc = tf.keras.layers.Concatenate()([left_2, right_2])\n",
    "encoded_question = tf.keras.layers.Dense(128, activation='relu')(conc)\n",
    "\n",
    "# Combine CNN and RNN to create the final model\n",
    "merged = tf.keras.layers.concatenate([encoded_question, encoded_image])\n",
    "output = Dense(num_classes, activation='softmax')(merged)\n",
    "model = Model(inputs=[image_input, question_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1611313718214,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "CBGKVJNYT6Zp",
    "outputId": "b90e587c-dc01-4885-dfb1-9ddd8387f862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 21)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 21, 100)      459500      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inception_resnet_v2 (Functional (None, 8, 8, 1536)   54336736    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          365568      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1536)         0           inception_resnet_v2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1792)         0           lstm[0][0]                       \n",
      "                                                                 global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 58)           103994      concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 55,265,798\n",
      "Trainable params: 469,562\n",
      "Non-trainable params: 54,796,236\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4Lw7k0pT6Zp"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_ihm4kvT6Zp"
   },
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3 \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9E1cbju78Iz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join('/content/drive/My Drive/NeuralNetworks/', 'classification_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "model_name = 'InceptionResNet+Glove_base'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name)\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                   save_weights_only=True)  \n",
    "\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
    "    callbacks.append(es_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "As suggested in Keras documentation, I do a first training keeping the base freezed, and then i proceed with the final fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4957643,
     "status": "ok",
     "timestamp": 1611328805320,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "1U8piETzcQr5",
    "outputId": "b4404e5a-26bb-47e8-f443-00715cb74406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1378/1378 [==============================] - 12287s 9s/step - loss: 1.9953 - accuracy: 0.3722 - val_loss: 1.4516 - val_accuracy: 0.4522\n",
      "Epoch 2/3\n",
      "1379/1378 [==============================] - ETA: 0s - loss: 1.4524 - accuracy: 0.4355Epoch 3/3\n",
      "1378/1378 [==============================] - 1252s 908ms/step - loss: 1.3141 - accuracy: 0.4771 - val_loss: 1.2755 - val_accuracy: 0.5045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb9aad92e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first training with the freezed base\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=100, \n",
    "          steps_per_epoch=len(dataset)/batch_size,\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(dataset_valid)/batch_size,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90450,
     "status": "ok",
     "timestamp": 1611329656204,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "cGQWN2EabTwe",
    "outputId": "ca3298f0-2356-4784-9c6c-7404072b993a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyNeuralNetworks/InceptionResnet+GLoVe_base/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyNeuralNetworks/InceptionResnet+GLoVe_base/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/content/drive/My Drive/NeuralNetworks/InceptionResnet+GLoVe_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1611332725823,
     "user": {
      "displayName": "Michele Bellomo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqEVViCWVD-iaTARN3gEA3KLZiRpDkXrCuC_Q1=s64",
      "userId": "00831375262492985479"
     },
     "user_tz": -60
    },
    "id": "CPACXZdCNEVF",
    "outputId": "137e20f7-ee5c-4bd7-bce3-8a49e714b3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 21)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 21, 100)      459500      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inception_resnet_v2 (Functional (None, 8, 8, 1536)   54336736    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          365568      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1536)         0           inception_resnet_v2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1792)         0           lstm[0][0]                       \n",
      "                                                                 global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 58)           103994      concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 55,265,798\n",
      "Trainable params: 7,731,834\n",
      "Non-trainable params: 47,533,964\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We perform fine tuning\n",
    "# ------------\n",
    "base.trainable = True\n",
    "unfreeze=False\n",
    "for layer in base.layers:\n",
    "  layer.trainable=False\n",
    "  if unfreeze and not (isinstance(layer, tf.keras.layers.BatchNormalization)):\n",
    "    layer.trainable=True\n",
    "  if layer.name=='block8_8_ac':\n",
    "    unfreeze=True\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=metrics, optimizer=tf.keras.optimizers.Adam(1e-4))  # Uso un learning rate più basso\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIjBbBzPEIq4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join('/content/drive/My Drive/NeuralNetworks/', 'classification_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "model_name = 'InceptionResNet+Glove'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name)\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                   save_weights_only=True)  \n",
    "\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    callbacks.append(es_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ha0XA_nYvDlN"
   },
   "outputs": [],
   "source": [
    "model.fit(x=train_dataset,\n",
    "          epochs=100, \n",
    "          steps_per_epoch=len(dataset)/batch_size,\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(dataset_valid)/batch_size,\n",
    "          callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VQA_InceptionResNet+GLoVe_bidirectional.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
